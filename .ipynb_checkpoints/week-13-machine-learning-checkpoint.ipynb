{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aea4d09-f1d5-41fd-ad9b-575d3ea6d115",
   "metadata": {},
   "source": [
    "# Week-13: Classification Task in Python\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* Welcome back!\n",
    "* Today, we will go over a classification example using `skicit-learn` package in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12028f21-bd8b-464a-899f-0acfe3e41a8a",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "* HW8 Q1: The location of files are misplaced. Suppose that `python_proj` is your working directory, <br> `HW8_main.py` should be put right under `python_proj`, while `HW8Fun.py` should be put under `self_py_fun` folder.\n",
    "* Interpretation of parameters of the linear model is not correct:\n",
    "* <img src=\"figures/HW8_linear_model_output.png\" alt=\"drawing\" width=\"500\"/>\n",
    "* For continuous covariate, i.e., CTQ total score, you should write:\n",
    "    * One score increase in CTQ total score, on average, corresponds to a 0.042 score increase in PCL5 score at intake, adjusting for other covariates (p=0.025, 95% CI: [0.003, 0.081]).\n",
    "* For categorical covariate, i.e., military rank, you should have reference group:\n",
    "    * Patients who are officers, on average, had lower PCL5 score at intake by 3.06 than patients who are enlisted, adjusting for other covariates (p=0.022, 95% CI: [0.44, 5.67]). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa492eb-75f3-4984-89d1-3f8dbc75c1e1",
   "metadata": {},
   "source": [
    "## Import data\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* `Scikit-learn`, known as `sklearn`, is an open-source, robust library for machine learning in Python.\n",
    "* It is created to streamline the process of implementing machine learning and statistical models in Python.\n",
    "* The package comes with standard machine learning datasets, and you can import it without downloading them from an external website or database.\n",
    "* Since we will go over a classification example, we will be using the [`wine dataset`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine) (Click it for more information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "223e4dda-3948-42c5-a85f-cf78f2313181",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy.sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_wine\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/__init__.py:73\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# `_distributor_init` allows distributors to run custom init code.\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# For instance, for the Windows wheel, this is used to pre-load the\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# vcomp shared library runtime for OpenMP embedded in the sklearn/.libs\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401 E402\u001b[39;00m\n\u001b[32m     70\u001b[39m     __check_build,\n\u001b[32m     71\u001b[39m     _distributor_init,\n\u001b[32m     72\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_show_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m     76\u001b[39m _submodules = [\n\u001b[32m     77\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcalibration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     78\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcluster\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    114\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcompose\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    115\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py:20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_metadata_requests\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_missing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_scalar_nan\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_repr_html\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ReprHTMLMixin, _HTMLDocumentationLinkMixin\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/__init__.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m metadata_routing\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_bunch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_chunking\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_indexing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     17\u001b[39m     _safe_indexing,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     18\u001b[39m     resample,\n\u001b[32m     19\u001b[39m     shuffle,\n\u001b[32m     20\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/_chunking.py:11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[32m     15\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumbers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Integral, Real\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'scipy.sparse'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7784c3c-f727-4d4f-9059-d60534adb560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa967e98-158c-4c66-9884-9f1dae36d3f0",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "* Executing the above code returns a dictionary-like object (we just learned!) that contains data and metadata.\n",
    "    * **Metadata**: This is a terminology for data dictionary, i.e., a description of the data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7937920-8ae3-4389-9b6f-92b435c5da53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to a Pandas dataframe\n",
    "wine_df = pd.DataFrame(wine_data.data, columns=wine_data.feature_names)\n",
    "\n",
    "# Add the target label (add a new column)\n",
    "wine_df['target'] = wine_dat\n",
    "\n",
    "# Preview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992c4669-c36c-4440-abda-1f44904503c8",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* Before conducting any data analysis, always check the quality of the dataset with exploratory data analysis.\n",
    "* You can call `.info()` method to print out a summary of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d92a6cb-135f-4c9e-b6b1-f1756f95a7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "666a1c0f-62e8-41fb-b99f-c0805b20846c",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "* There are 178 data samples with 14 columns including the target column (output that we would like to predict).\n",
    "* Luckily, no missing values are in our dataset from `Non-Null Count`.\n",
    "* All features are `float64` except for target column.\n",
    "* The dataset consumes 19.6 KB of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff288d89-e926-4e28-a68f-af964852220a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "236003c9-dd43-46d1-a97d-73fae18cb918",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "* Since `target` is a categorical variable, we check the frequency and proportion using `.value_counts()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c004e86-3ebf-4f45-8726-e1e632fedc0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a0d8b1b-d433-4312-acfc-50efc4e66f65",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* Preprocessing is important prior to applying machine learning algorithms.\n",
    "    * Check missing values, outliers, duplicates, errors, and data types.\n",
    "    * Avoid \"Garbage in, garbage out.\"\n",
    "* Machine learning models typically require numerical inputs.\n",
    "* Another practice is to standardize the input (via Z-transform) to make predictors more comparable. \n",
    "    * We do not want predictor A has a magnitude of 10000, while predictor B has a magnitude of 0.1.\n",
    "    * We can achieve the goal using `StandardScaler()` class.\n",
    "    * Each value goes through the following transformation columnwise, i.e., $x = (x - x_{mean})/x_{sd}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30d2b253-5ee5-4594-9707-5004ced1dab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to import standardscaler (code should be written in the beginning of the Jupyter notebook).\n",
    "# Split data into features (input) and label (output)\n",
    "\n",
    "\n",
    "# Always make a copy to avoid making changes on the raw data (when you have sufficient amount of memory).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9da298-4547-409f-9ff5-f67e1329648c",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "<img src=\"figures/sklearn_flowchart_1.png\" alt=\"drawing\" width=\"900\"/>\n",
    "    \n",
    "* In this flowchart, no output data are involved. We use `.transform()` in the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7eacfaa-6c63-40b9-bd42-d12ed548946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate scaler and fit on features\n",
    "\n",
    "\n",
    "# apply changes to training data\n",
    "# and update parameters (in this case, no model parameters are available, so this is optional)\n",
    "\n",
    "\n",
    "# apply changes to any data and assign it with another variable\n",
    "\n",
    "\n",
    "# view the transformed output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a459bb-862e-4c49-84c2-47aa0aff4a8e",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* As we previously mentioned, we need to have training and testing set when we perform classification tasks.\n",
    "* If rows of input data are independent of each other, we can randomly select training and testing set.\n",
    "* Sklearn package has a built-in function called `train_test_split()`.\n",
    "* We usually set 70% data to train and 30% to test. The exact ratio vary depending on the volume of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20bc0777-625c-4780-adab-b7f81478d0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to import train_test_split in the beginning\n",
    "\n",
    "\n",
    "# Check the splits are correct\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0c7783-41c7-43aa-bdbb-e6284aea7f24",
   "metadata": {},
   "source": [
    "### Model building\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* Sklearn has numerous built-in classification methods. We will demonstrate a couple of methods including\n",
    "    * logistic regression\n",
    "    * support vector machine\n",
    "    * decision tree classifier\n",
    "    \n",
    "* <img src=\"figures/sklearn_flowchart_2.png\" alt=\"drawing\" width=\"900\"/>\n",
    "\n",
    "    * In this flowchart, both input and output (in the training set) are involved, so `.predict()` is used finally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb40ecea-5e32-4d35-85b9-14a2db776698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniatiating the models \n",
    "# Sometimes, you need to modify the parameters inside each of the function.\n",
    "# If not, the model will use its default values.\n",
    "# write one model and the rest two are completed by students\n",
    "\n",
    "\n",
    "# Training the models \n",
    "\n",
    "\n",
    "# Making predictions with each model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7134d7-885e-4352-b536-4b5340e0fc39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddc6d21d-9290-45a1-937e-460b36048966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can view the probability vector per measure per method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed927f6-e723-4ed2-a972-0ba05add1976",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* In our case, we will use `classification_report()` to build a text report showing main classification metrics such as `precision`, `recall`, `f1_score`, `accuracy`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b856b675-5f55-48b6-8bcf-8ffec1ab6ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report (put it in the beginning)\n",
    "# Store model predictions in a dictionary\n",
    "# this makes it easier to iterate through each model\n",
    "# and print the results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9de809-15bc-440f-b76d-bfdb164fbdba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83993ee6-7db1-441a-b46a-d21a986e3168",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "The reported averages include \n",
    "\n",
    "* (sample) average (only for multilabel classification). \n",
    "* macro average (averaging the unweighted mean per label), \n",
    "* weighted average (averaging the support-weighted mean per label).\n",
    "\n",
    "Which method performs the best?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
